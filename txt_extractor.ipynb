{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "created by Finn Buchrieser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "tqdm.pandas(mininterval = 3)\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine why there are NA values in the combined df in the date column but there arent any in the individual dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_split_abstracts(df, target_directory, split=\"both\", combine_dates = False, sample_size = 450, sampling = True, text_or_values = \"values\"):\n",
    "    \n",
    "    science_list = df[\"Science\"].unique()\n",
    "    # the function i repeated for each field of science\n",
    "    for t,q in enumerate(science_list):\n",
    "        \n",
    "        df_filtered_science = df[df['Science'] == science_list[t]]\n",
    "\n",
    "        # this code splits abstracts in three parts by splitting each abstract into a list\n",
    "        # and then joining the first third, second third and third third of the list\n",
    "\n",
    "        df_filtered_science[\"Content\"] = df_filtered_science[\"Content\"].progress_apply(lambda x: x.split())\n",
    "\n",
    "        df_filtered_science[\"split_abstracts_1\"] = df_filtered_science[\"Content\"].progress_apply(lambda x: \" \".join(x[:len(x)//3]))\n",
    "        df_filtered_science[\"split_abstracts_2\"] = df_filtered_science[\"Content\"].progress_apply(lambda x: \" \".join(x[len(x)//3:((len(x)//3)*2)]))\n",
    "        df_filtered_science[\"split_abstracts_3\"] = df_filtered_science[\"Content\"].progress_apply(lambda x: \" \".join(x[((len(x)//3)*2):]))\n",
    "\n",
    "\n",
    "\n",
    "        if combine_dates == False:\n",
    "            if sampling == True:\n",
    "                # sorting by positivity and date\n",
    "                # and only keeping the amount for each that the smallest\n",
    "                # time frame has or 1000 sample if possible\n",
    "\n",
    "                df_high_values = df_filtered_science[df_filtered_science[\"Positivity\"] >= df_filtered_science[\"Positivity\"].quantile(.75)]\n",
    "                df_low_values = df_filtered_science[df_filtered_science[\"Positivity\"] <= df_filtered_science[\"Positivity\"].quantile(.25)]\n",
    "\n",
    "\n",
    "                df_low_values_80_85 = df_low_values[(df_low_values[\"Publish_Date\"] <= \"1985-12-31\") & (df_low_values[\"Publish_Date\"] > \"1980-01-01\")]\n",
    "                df_low_values_85_90 = df_low_values[(df_low_values[\"Publish_Date\"] >= \"1985-01-01\") & (df_low_values[\"Publish_Date\"] < \"1990-01-01\")]\n",
    "                df_low_values_90_95 = df_low_values[(df_low_values[\"Publish_Date\"] >= \"1990-01-01\") & (df_low_values[\"Publish_Date\"] < \"1995-01-01\")]\n",
    "                df_low_values_95_00 = df_low_values[(df_low_values[\"Publish_Date\"] >= \"1995-01-01\") & (df_low_values[\"Publish_Date\"] < \"2000-01-01\")]\n",
    "                df_low_values_00_05 = df_low_values[(df_low_values[\"Publish_Date\"] >= \"2000-01-01\") & (df_low_values[\"Publish_Date\"] < \"2005-01-01\")]\n",
    "                df_low_values_05_10 = df_low_values[(df_low_values[\"Publish_Date\"] >= \"2005-01-01\") & (df_low_values[\"Publish_Date\"] < \"2010-01-01\")]\n",
    "                df_low_values_10_15 = df_low_values[(df_low_values[\"Publish_Date\"] >= \"2010-01-01\") & (df_low_values[\"Publish_Date\"] < \"2015-01-01\")]\n",
    "                df_low_values_15_20 = df_low_values[(df_low_values[\"Publish_Date\"] >= \"2015-01-01\") & (df_low_values[\"Publish_Date\"] < \"2020-01-01\")]\n",
    "\n",
    "                df_high_values_80_85 = df_high_values[(df_high_values[\"Publish_Date\"] <= \"1985-12-31\") & (df_high_values[\"Publish_Date\"] > \"1980-01-01\")]\n",
    "                df_high_values_85_90 = df_high_values[(df_high_values[\"Publish_Date\"] >= \"1985-01-01\") & (df_high_values[\"Publish_Date\"] < \"1990-01-01\")]\n",
    "                df_high_values_90_95 = df_high_values[(df_high_values[\"Publish_Date\"] >= \"1990-01-01\") & (df_high_values[\"Publish_Date\"] < \"1995-01-01\")]\n",
    "                df_high_values_95_00 = df_high_values[(df_high_values[\"Publish_Date\"] >= \"1995-01-01\") & (df_high_values[\"Publish_Date\"] < \"2000-01-01\")]\n",
    "                df_high_values_00_05 = df_high_values[(df_high_values[\"Publish_Date\"] >= \"2000-01-01\") & (df_high_values[\"Publish_Date\"] < \"2005-01-01\")]\n",
    "                df_high_values_05_10 = df_high_values[(df_high_values[\"Publish_Date\"] >= \"2005-01-01\") & (df_high_values[\"Publish_Date\"] < \"2010-01-01\")]\n",
    "                df_high_values_10_15 = df_high_values[(df_high_values[\"Publish_Date\"] >= \"2010-01-01\") & (df_high_values[\"Publish_Date\"] < \"2015-01-01\")]\n",
    "                df_high_values_15_20 = df_high_values[(df_high_values[\"Publish_Date\"] >= \"2015-01-01\") & (df_high_values[\"Publish_Date\"] < \"2020-01-01\")]\n",
    "\n",
    "\n",
    "                to_text_list = [df_low_values_80_85, df_low_values_85_90, df_low_values_90_95, df_low_values_95_00, df_low_values_00_05, df_low_values_05_10, df_low_values_10_15,\n",
    "                                df_low_values_15_20, df_high_values_80_85, df_high_values_85_90, df_high_values_90_95, df_high_values_95_00, df_high_values_00_05, df_high_values_05_10,\n",
    "                                df_high_values_10_15, df_high_values_15_20]\n",
    "\n",
    "                # a sample is created for each time frame and valence\n",
    "                sampel_size = sample_size\n",
    "                for y, i in enumerate(to_text_list):\n",
    "                    to_text_list[y] = to_text_list[y].sample(sampel_size)\n",
    "\n",
    "                third_list = [1, 2, 3]\n",
    "\n",
    "                str_list  = [\"df_low_values_80_85\", \"df_low_values_85_90\", \"df_low_values_90_95\", \"df_low_values_95_00\", \"df_low_values_00_05\", \"df_low_values_05_10\", \"df_low_values_10_15\",\n",
    "                            \"df_low_values_15_20\", \"df_high_values_80_85\", \"df_high_values_85_90\", \"df_high_values_90_95\", \"df_high_values_95_00\", \"df_high_values_00_05\", \"df_high_values_05_10\",\n",
    "                            \"df_high_values_10_15\", \"df_high_values_15_20\"]\n",
    "                # the \"text\" option writes each text in the sample into a text file, numbered from 0 to sample_size\n",
    "                # the \"values\" option writes the values of the sample into a table\n",
    "                # the split option decides wether the text is split into three different files of equal size, written into one file or both\n",
    "                if split == \"thirds\" or split == \"both\":\n",
    "                    for y, element in enumerate(to_text_list):\n",
    "                            \n",
    "                            for z in third_list:\n",
    "\n",
    "                                for i in range(sample_size):\n",
    "\n",
    "                                    if text_or_values == \"text\" or text_or_values == \"both\":\n",
    "                                        with open (f\"{target_directory}\\\\same_size_5_year_all_sciences_thirds\\\\{q[0:3].lower()}_{z}_{str_list[y]}_{i}.txt\", \"w\", encoding = \"utf-8\") as file:\n",
    "                                            file.write(element[f\"split_abstracts_{z}\"].iloc[i])\n",
    "\n",
    "                                    if text_or_values == \"values\" or text_or_values == \"both\":\n",
    "                                         i[]\n",
    "                                        \n",
    "                # the \"text\" option writes each text in the sample into a text file, numbered from 0 to sample_size\n",
    "                # the \"values\" option writes the values of the sample into a table\n",
    "                # the split option decides wether the text is split into three different files of equal size, written into one file or both\n",
    "                if split == \"whole\" or split == \"both\":\n",
    "                    for y, element in enumerate(to_text_list): \n",
    "\n",
    "                            for i in range(sample_size):\n",
    "\n",
    "                                if text_or_values == \"text\" or text_or_values == \"both\":\n",
    "                                    with open (f\"{target_directory}\\\\same_size_5_year_all_sciences_whole_texts\\\\{q[0:3].lower()}_{str_list[y]}_{i}.txt\", \"w\", encoding = \"utf-8\") as file:\n",
    "                                        file.write(\" \".join(element[\"Content\"].iloc[i]))\n",
    "\n",
    "                                if text_or_values == \"values\" or text_or_values == \"both\":\n",
    "\n",
    "\n",
    "\n",
    "        if combine_dates == True:\n",
    "            if sampling == False:\n",
    "                df_high_values = df_filtered_science[df_filtered_science[\"Positivity\"] >= df_filtered_science[\"Positivity\"].quantile(.75)]\n",
    "                df_low_values = df_filtered_science[df_filtered_science[\"Positivity\"] <= df_filtered_science[\"Positivity\"].quantile(.25)]\n",
    "                third_list = [1, 2, 3]\n",
    "                to_text_list = [df_low_values, df_high_values]\n",
    "                str_list = [\"df_low_values\", \"df_high_values\"]\n",
    "                \n",
    "                if thirds == True:\n",
    "                    for y, element in enumerate(to_text_list):\n",
    "                            \n",
    "                            for z in third_list:\n",
    "\n",
    "                                for i in range(len(element)):\n",
    "                                    \n",
    "                                    with open (f\"{target_directory}\\\\same_size_5_year_all_sciences_thirds\\\\{q[0:3].lower()}_{z}_{str_list[y]}_{i}.txt\", \"w\", encoding = \"utf-8\") as file:\n",
    "                                        file.write(element[f\"split_abstracts_{z}\"].iloc[i])\n",
    "\n",
    "                for y, element in enumerate(to_text_list): \n",
    "\n",
    "                        for i in range(len(element)):\n",
    "                            \n",
    "                            with open (f\"{target_directory}\\\\same_size_5_year_all_sciences_whole_texts\\\\{q[0:3].lower()}_{str_list[y]}_{i}.txt\", \"w\", encoding = \"utf-8\") as file:\n",
    "                                file.write(\" \".join(element[\"Content\"].iloc[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"E:\\Speechgraph\\Preprocesed_Ed_Data_Df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace edlinger dict in abstracts\n",
    "\n",
    "\n",
    "edlinger_list = ['beneficial', 'benefit', 'benefits', 'better', 'effectively', 'efficient', 'excellent', 'greater',\n",
    "                 'help', 'importance', 'important', 'improve', 'improved', 'improvement', 'improvements', 'improving',\n",
    "                 'increase', 'increased', 'interest', 'novel', 'optimal', 'opportunity', 'promise', 'progress',\n",
    "                 'significance', 'significantly', 'strong', 'strongly', 'successfully', 'supported', 'supporting',\n",
    "                 'supports', 'useful', 'valuable', 'well']\n",
    "\n",
    "def remove_edlinger_words(abstract):\n",
    "    split_abstract = abstract.split()\n",
    "    filtered_abstract = []\n",
    "    for word in split_abstract:\n",
    "        if word in edlinger_list:\n",
    "            word = \"wsdf8gfk00\"\n",
    "        filtered_abstract.append(word)\n",
    "    return \" \".join(filtered_abstract)\n",
    "\n",
    "df_list = [df_low_values_80, df_low_values_90, df_low_values_00, df_low_values_10, df_low_values_20,\n",
    "                 df_high_values_80, df_high_values_90, df_high_values_00, df_high_values_10, df_high_values_20]\n",
    "\n",
    "for dataf in df_list:\n",
    "    dataf[\"Abstract\"] = dataf[\"Abstract\"].progress_apply(lambda x: remove_edlinger_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove edlinger dict from abstracts\n",
    "\n",
    "\n",
    "edlinger_list = ['beneficial', 'benefit', 'benefits', 'better', 'effectively', 'efficient', 'excellent', 'greater',\n",
    "                 'help', 'importance', 'important', 'improve', 'improved', 'improvement', 'improvements', 'improving',\n",
    "                 'increase', 'increased', 'interest', 'novel', 'optimal', 'opportunity', 'promise', 'progress',\n",
    "                 'significance', 'significantly', 'strong', 'strongly', 'successfully', 'supported', 'supporting',\n",
    "                 'supports', 'useful', 'valuable', 'well']\n",
    "\n",
    "def remove_edlinger_words(abstract):\n",
    "    split_abstract = abstract.split()\n",
    "    filtered_abstract = [word for word in split_abstract if word not in edlinger_list]\n",
    "    return \" \".join(filtered_abstract)\n",
    "\n",
    "df_list = [df_low_values_80, df_low_values_90, df_low_values_00, df_low_values_10, df_low_values_20,\n",
    "                 df_high_values_80, df_high_values_90, df_high_values_00, df_high_values_10, df_high_values_20]\n",
    "\n",
    "for dataf in df_list:\n",
    "    dataf[\"Abstract\"] = dataf[\"Abstract\"].progress_apply(lambda x: remove_edlinger_words(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
